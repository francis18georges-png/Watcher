[ui]
mode = "Sur"
theme = "dark"
language = "fr"
autosave = true

[llm]
backend = "llama.cpp"
model = "smollm-135m-instruct-Q4_0"
host = "127.0.0.1:11434"
model_path = "models/llm/smollm-135m-instruct.Q4_0.gguf"
ctx = 2048
threads = null
max_tokens = 256
temperature = 0.2
system_prompt = "Tu es Watcher, un assistant de développement Python fonctionnant hors ligne. Fournis des réponses concises et fiables."
fallback_phrase = "Echo"

[dev]
logging = "debug"
trace_requests = false

[logging]
fallback_level = "INFO"

[planner]
default_platform = "windows"
default_license = "MIT"

[memory]
db_path = "memory/mem.db"
cache_size = 128
embed_model = "sentence-transformers/all-MiniLM-L6-v2"
embed_model_path = "models/embeddings/all-MiniLM-L6-v2"
summary_max_tokens = 512
retention_limit = 4096

[learn]
optimizer = "adam"
learning_rate = 0.1
reward_clip = 1.0

[intelligence]
mode = "offline"
curriculum = "default"

[data]
raw_dir = "datasets/raw"
processed_dir = "datasets/processed"
steps = {}

[training]
seed = 42
batch_size = 16
lr = 1e-4

[model]
name = "watcher"
revision = "0.1"
precision = "fp16"

[scraper]
rate_per_domain = 1.0
concurrency = 6
user_agent = "WatcherBot/1.0 (+https://github.com/francis18georges-png/Watcher)"

[dataset]
raw_dir = "datasets/raw"
processed_dir = "datasets/processed"

[embeddings]
backend = "local_faiss"

[database]
url = "sqlite+aiosqlite:///./data/watcher.db"
pool_size = 5
pool_timeout = 30
pool_recycle = 1800
echo = false
