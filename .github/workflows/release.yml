name: Release

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:

permissions:
  contents: write
  packages: write
  id-token: write

jobs:
  build:
    name: Build packages (${{ matrix.os }} / py${{ matrix.python }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-24.04
            python: "3.12"
            artifact_tag: linux-x86_64
            archive_ext: tar.gz
          - os: windows-2022
            python: "3.12"
            artifact_tag: windows-x86_64
            archive_ext: zip
    env:
      ARTIFACT_TAG: ${{ matrix.artifact_tag }}
      ARCHIVE_EXT: ${{ matrix.archive_ext }}
      ARTIFACT_DIR: ${{ github.workspace }}/release/${{ matrix.artifact_tag }}
      PYINSTALLER_DIST: ${{ github.workspace }}/pyinstaller-dist
      PYINSTALLER_BUILD: ${{ github.workspace }}/pyinstaller-build
      PYINSTALLER_SPEC: ${{ github.workspace }}/pyinstaller-spec
    steps:
      - name: Validate SemVer tag
        run: |
          python - <<'PY'
          import os
          import re
          import sys

          tag = os.environ.get("GITHUB_REF_NAME", "")
          if not re.fullmatch(r"v\d+\.\d+\.\d+", tag):
              sys.exit(f"Release tag '{tag}' must match vMAJOR.MINOR.PATCH")
          PY

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}
          cache: pip
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt

      - name: Configure reproducible build metadata
        shell: bash
        run: |
          python - <<'PY'
          from __future__ import annotations

          import os
          from datetime import datetime, timezone

          now = datetime.now(tz=timezone.utc)
          epoch = int(now.timestamp())
          env = {
              "SOURCE_DATE_EPOCH": str(epoch),
              "PYTHONHASHSEED": "0",
          }
          with open(os.environ["GITHUB_ENV"], "a", encoding="utf-8") as env_file:
              for key, value in env.items():
                  env_file.write(f"{key}={value}\n")
          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as handle:
              handle.write(f"build_timestamp={now.isoformat()}\n")
          PY

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install build pyinstaller cyclonedx-bom cyclonedx-py

      - name: Prepare build directories
        run: |
          python - <<'PY'
          import os
          from pathlib import Path

          for key in ("ARTIFACT_DIR", "PYINSTALLER_DIST", "PYINSTALLER_BUILD", "PYINSTALLER_SPEC"):
              path = Path(os.environ[key])
              path.mkdir(parents=True, exist_ok=True)
          PY

      - name: Build wheel and sdist
        run: |
          python -m build --outdir "${{ env.ARTIFACT_DIR }}"

      - name: Build standalone executable
        run: |
          python - <<'PY'
          import os
          import PyInstaller.__main__

          PyInstaller.__main__.run(
              [
                  "packaging/watcher.spec",
                  "--noconfirm",
                  "--distpath",
                  os.environ["PYINSTALLER_DIST"],
                  "--workpath",
                  os.environ["PYINSTALLER_BUILD"],
                  "--specpath",
                  os.environ["PYINSTALLER_SPEC"],
              ]
          )
          PY

      - name: Package executable archive
        run: |
          python - <<'PY'
          import os
          import tarfile
          import zipfile
          from pathlib import Path

          artifact_dir = Path(os.environ["ARTIFACT_DIR"])
          dist_root = Path(os.environ["PYINSTALLER_DIST"]) / "Watcher"
          if not dist_root.exists():
              raise SystemExit(f"PyInstaller output '{dist_root}' is missing")

          archive_stem = f"watcher-{os.environ['ARTIFACT_TAG']}"
          archive_ext = os.environ["ARCHIVE_EXT"]
          archive_path = artifact_dir / f"{archive_stem}.{archive_ext}"

          if archive_path.exists():
              archive_path.unlink()

          if archive_ext == "zip":
              with zipfile.ZipFile(archive_path, "w", compression=zipfile.ZIP_DEFLATED) as archive:
                  for path in sorted(dist_root.rglob("*")):
                      if path.is_file():
                          archive.write(path, path.relative_to(dist_root.parent).as_posix())
          elif archive_ext == "tar.gz":
              with tarfile.open(archive_path, "w:gz") as archive:
                  archive.add(dist_root, arcname="Watcher")
          else:
              raise SystemExit(f"Unsupported archive extension: {archive_ext}")
          PY

      - name: Generate CycloneDX SBOM
        run: |
          python - <<'PY'
          import os
          import subprocess
          from pathlib import Path

          artifact_dir = Path(os.environ["ARTIFACT_DIR"])
          sbom_path = artifact_dir / f"watcher-{os.environ['ARTIFACT_TAG']}-sbom.json"
          subprocess.run(
              [
                  "cyclonedx-py",
                  "environment",
                  "--format",
                  "json",
                  "--output-file",
                  str(sbom_path),
              ],
              check=True,
          )
          PY

      - name: Compute artifact checksums
        run: |
          python - <<'PY'
          import hashlib
          import os
          from pathlib import Path

          artifact_dir = Path(os.environ["ARTIFACT_DIR"])
          lines: list[str] = []
          for file in sorted(artifact_dir.iterdir()):
              if file.is_file() and not file.name.startswith("checksums-"):
                  digest = hashlib.sha256(file.read_bytes()).hexdigest()
                  lines.append(f"{digest}  {file.name}")
          checksum_path = artifact_dir / f"checksums-{os.environ['ARTIFACT_TAG']}.txt"
          checksum_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
          PY

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-${{ matrix.artifact_tag }}
          path: ${{ env.ARTIFACT_DIR }}
          if-no-files-found: error

  collate:
    name: Collate release assets
    needs: build
    runs-on: ubuntu-24.04
    outputs:
      checksums-sha256: ${{ steps.aggregate.outputs.checksum_sha }}
    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          path: dist
          merge-multiple: true

      - name: Aggregate checksums
        id: aggregate
        run: |
          python - <<'PY'
          import hashlib
          import json
          import os
          from pathlib import Path

          root = Path("dist")
          files = []
          for path in sorted(root.rglob("*")):
              if not path.is_file():
                  continue
              if path.name.startswith("checksums-") and path.suffix == ".txt":
                  path.unlink()
                  continue
              files.append(path)

          checksums = []
          predicate = []
          for file in files:
              digest = hashlib.sha256(file.read_bytes()).hexdigest()
              rel = file.relative_to(root).as_posix()
              checksums.append(f"{digest}  {rel}")
              predicate.append({"name": rel, "sha256": digest})

          checksum_file = root / "checksums.txt"
          checksum_file.write_text("\n".join(checksums) + "\n", encoding="utf-8")

          predicate_file = root / "checksums-predicate.json"
          predicate_file.write_text(
              json.dumps(
                  {
                      "type": "watcher.checksums",
                      "subject": predicate,
                  },
                  indent=2,
              )
              + "\n",
              encoding="utf-8",
          )

          digest = hashlib.sha256(checksum_file.read_bytes()).hexdigest()
          with Path(os.environ["GITHUB_OUTPUT"]).open("a", encoding="utf-8") as handle:
              handle.write(f"checksum_sha={digest}\n")
          PY

      - name: Install cosign
        uses: sigstore/cosign-installer@v3.5.0

      - name: Sign global checksums
        run: |
          cosign sign-blob \
            --yes \
            --output-signature dist/checksums.txt.sig \
            dist/checksums.txt

      - name: Generate cosign attestation
        run: |
          cosign attest \
            --yes \
            --predicate dist/checksums-predicate.json \
            --type https://watcher.dev/checksums \
            --output-file dist/checksums.intoto.jsonl \
            ./dist/checksums.txt

      - name: Remove temporary predicate
        run: rm -f dist/checksums-predicate.json

      - name: Upload collated artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-final
          path: dist
          if-no-files-found: error

  generate-provenance:
    name: Generate SLSA provenance
    needs: collate
    permissions:
      actions: read
      id-token: write
      contents: write
    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.10.0
    with:
      build-artifacts: release-final
      provenance-subject-name: checksums.txt
      provenance-subject-digest: sha256:${{ needs.collate.outputs.checksums-sha256 }}
    secrets: inherit

  publish:
    name: Publish GitHub release
    needs:
      - collate
      - generate-provenance
    runs-on: ubuntu-24.04
    permissions:
      contents: write
      packages: write
    steps:
      - name: Download collated artifacts
        uses: actions/download-artifact@v4
        with:
          name: release-final
          path: dist

      - name: Download SLSA provenance
        uses: actions/download-artifact@v4
        with:
          path: provenance
          merge-multiple: true

      - name: Prepare provenance bundle
        run: |
          python - <<'PY'
          import os
          from pathlib import Path

          target = Path("dist") / "checksums.slsa.intoto.jsonl"
          for path in Path("provenance").rglob("*.intoto.jsonl"):
              path.replace(target)
              break
          else:
              raise SystemExit("Provenance file not found")
          PY

      - name: Prepare release asset list
        id: assets
        run: |
          python - <<'PY'
          import os
          from pathlib import Path

          files = [
              str(path)
              for path in sorted(Path("dist").rglob("*"))
              if path.is_file()
          ]
          token = "WATCHER_FILES"
          with Path(os.environ["GITHUB_OUTPUT"]).open("a", encoding="utf-8") as handle:
              handle.write(f"files<<{token}\n")
              handle.write("\n".join(files))
              handle.write(f"\n{token}\n")
          PY

      - name: Publish release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ github.ref_name }}
          name: Watcher ${{ github.ref_name }}
          generate_release_notes: true
          fail_on_unmatched_files: true
          files: ${{ steps.assets.outputs.files }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
